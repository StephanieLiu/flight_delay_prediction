{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Houssem Ben Braiek, Emilio Rivera-Landos, IVADO, SEMLA\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import os\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "MLFLOW_URI = os.getenv(\"MLFLOW_URI\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import mlflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.suites import full_suite\n",
    "from deepchecks.tabular.suites import model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flight_delay import pre_processing,train_utils,features\n",
    "from flight_delay.mlflow.registry import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, dvc_info = load_dataset_from_localfs(splits_data_dir=\"../data/splits/reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flight_delay import pre_processing,train_utils,features\n",
    "data_path = '../data/flights_delay_dataset.csv'\n",
    "df_flights = pre_processing.load_data(data_path)\n",
    "df_ref = df_flights[df_flights[\"flight_year\"]==2019]\n",
    "# df_ref.to_csv(\"../data/reference_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = \"2019-01-01\"\n",
    "train_end   = \"2019-10-01\"\n",
    "\n",
    "test_start = \"2019-10-01\"\n",
    "test_end   = \"2020-01-01\"\n",
    "\n",
    "target_col = \"ARR_DELAY\"\n",
    "split_col  = \"FL_DATE\"\n",
    "\n",
    "X_train,y_train,X_test,y_test = train_utils.train_test_split_func(df_ref,train_start,train_end,test_start,test_end,split_col,target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, model_version = \"lightGBM\", \"1\"\n",
    "model_under_test = load_model(MLFLOW_URI, model_name, model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = features.numerical_cols\n",
    "categorical_cols = features.categorical_cols\n",
    "time_cols = features.time_cols\n",
    "passthrough_cols = features.passthrough_cols\n",
    "\n",
    "features_list = numerical_cols + categorical_cols + time_cols + passthrough_cols\n",
    "\n",
    "predicted_var = \"predicted_arrival_delay\"\n",
    "\n",
    "ds_train = Dataset(X_train[features_list], label=y_train, cat_features=categorical_cols)\n",
    "ds_test =  Dataset(X_test[features_list],  label=y_test, cat_features=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = full_suite()\n",
    "suite_result = suite.run(train_dataset=ds_train, \n",
    "                         test_dataset=ds_test, \n",
    "                         model=model_under_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suite_result.show()\n",
    "suite_result.show_in_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_suite = model_evaluation()\n",
    "suite_result = suite.run(train_dataset=ds_train, \n",
    "                         test_dataset=ds_test, \n",
    "                         model=model_under_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_result.show_in_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
